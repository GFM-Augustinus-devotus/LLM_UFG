As métricas para chatbot são: 
taxa de resolução, retenção, compreensão e transbordo; 
nível de satisfação do usuário; tempo de conversa, resposta e resolução; 
qualidade; eficiência; atendimentos iniciados e concluídos e custo.

A taxa de resolução de chatbot, como o nome já indica, é o número de vezes que a ferramenta resolveu as solicitações dos usuários.
Digamos que a ferramenta atendeu 100 usuários em um período. Desses, apenas 10 tiveram seus problemas resolvidos.
Ou seja, 10% indica que a taxa de resolução está baixa e, nesse cenário, é preciso pensar em estratégias para melhorar a resolutividade.
O ideal é que essa métrica traga números altos, pois isso indica que seu chatbot está funcionando como deveria

Outra métrica vital para chatbot é a taxa de retenção. Isto é, quantos usuários seguem até o final da interação, considerando o número total de atendimentos.
Ela serve para analisar a qualidade e eficiência das interações e até descobrir o que leva à desistência no meio do caminho. 
Afinal, se o contato não agrada os clientes, é óbvio que eles não querem utilizar esse canal.
Só para exemplificar, com essa métrica, você percebe que apenas 30% dos clientes prosseguem com o atendimento após a quarta pergunta. 
Logo, entende-se que as interações são muito longas ou os consumidores não querem responder tantas questões. Ficou claro? De todo modo, não esqueça de sempre monitorar esse ponto.


----------> Estudo dos Chunks

Chunks retornados: 3
Tamanho total dos textos: 32.920 caracteres (aproximadamente 5.000 a 6.000 tokens, dentro do limite do modelo gpt-3.5-turbo).
Os chunks grandes (por exemplo, com 6.000, 21.000, 26.000 caracteres) contêm o texto completo das resoluções e documentos, não apenas títulos ou sumários.
Os chunks pequenos são apenas introduções, mas agora não dominam a busca.
O que isso significa?
O retriever está conseguindo acessar o conteúdo real dos documentos.
O modelo agora tem contexto suficiente para responder perguntas sobre as resoluções e textos completos.
Você não deve mais ter problemas de contexto insuficiente ou excesso de tokens (desde que mantenha k=3 e chunk_size em torno de 2000).
Dicas finais
Se alguma resposta vier muito genérica, pode ajustar o chunk_size para 1500 ou 1000 para mais precisão.
Se voltar a dar erro de contexto, reduza k para 2.
Se quiser respostas mais específicas, pode ajustar o prompt para pedir respostas mais objetivas.

chunk_size
Define o tamanho (em caracteres ou tokens) de cada pedaço ("chunk") em que o texto será dividido para indexação e busca.
Exemplo: chunk_size=1000 cria pedaços de até 1000 caracteres.

chunk_overlap
Define quantos caracteres (ou tokens) do final de um chunk serão repetidos no início do próximo.
Isso garante que informações que ficam na "fronteira" entre chunks não sejam perdidas.
Exemplo: chunk_overlap=50 faz com que os últimos 50 caracteres de um chunk também estejam no início do próximo.

search_kwargs
São argumentos passados para o método de busca do retriever.
O mais comum é o k, que define quantos chunks/documentos mais relevantes devem ser retornados para cada pergunta.
Exemplo: search_kwargs={"k": 2} retorna os 2 chunks mais similares à consulta.